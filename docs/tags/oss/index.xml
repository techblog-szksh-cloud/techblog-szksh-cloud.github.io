<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>oss on melody</title>
    <link>https://techblog.szksh.cloud/tags/oss/</link>
    <description>Recent content in oss on melody</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp</language>
    <lastBuildDate>Thu, 18 Nov 2021 20:21:57 +0900</lastBuildDate><atom:link href="https://techblog.szksh.cloud/tags/oss/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>aqua の最近の update (v0.7.4 ~ v0.7.16)</title>
      <link>https://techblog.szksh.cloud/update-aqua-v0.7.16/</link>
      <pubDate>Thu, 18 Nov 2021 20:21:57 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/update-aqua-v0.7.16/</guid>
      <description>以前 aqua v0.7.3 がリリースされた際に aqua で組織・チームのツール群を管理 という記事を書きました。 あれからもうすぐ 2 ヶ月になり、最新バージョンは v0.7.16 になりました。 そこで v0.7.4 ~ v0.7.16 の間の更新と、関連 repository の更新を幾つか(全部ではない)紹介します。
基本的に Release Note に書いてある内容です。
 GitHub の Access Token が基本的に不要になりました Homebrew で install できるようになりました aqua.yaml がより簡潔に書けるようになりました aqua.yaml の packages を他のローカルのファイルから import できるようになりました aqua.yaml をディレクトリの階層的にネストできるようになりました aqua which コマンドをサポートしました github_archive, github_content type をサポートしました (advanced) バージョンによってパッケージの type が変更された場合にも対応できるようになりました Standard Registry の package の数が 139 =&amp;gt; 220 になりました。 aqua のための CircleCI Orb をリリースしました  GitHub の Access Token が基本的に不要になりました private repository から package をインストール場合は当然必要ですが、そうでなければ不要になりました。 これにより、 aqua を導入するハードルが下がりましたし、 GitHub API の Rate Limit に引っかかることが基本的になくなりました。</description>
    </item>
    
    <item>
      <title>2021-10 やったこと</title>
      <link>https://techblog.szksh.cloud/what-i-did-2021-10/</link>
      <pubDate>Tue, 26 Oct 2021 20:43:03 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/what-i-did-2021-10/</guid>
      <description>Job  AWS SSO の導入  Google アカウントで AWS へサインインできるように設定 AWS SSO の Terraform 管理 ssosync を Lambda で定期実行 開発者向けの移行ガイドの作成し、実際に案内 terraform, kubectl などのツールで AWS にアクセスできるかの検証   AWS WAF の COUNT, BLOCK の log を Firehose, Lambda で抽出 akoi を aqua にリプレース  Blog  2021-10-13: HashiTalks Japan 2021 で弊プロダクトの Terraform Platform について登壇しました  OSS https://github.com/pulls?q=is%3Aclosed+is%3Apublic+is%3Apr+author%3Asuzuki-shunsuke+archived%3Afalse+created%3A2021-10-01..2021-10-31+
 Profile などの更新: https://github.com/suzuki-shunsuke/suzuki-shunsuke GitHub Actions の開発 自作ツールを Homebrew でインストールできるようにした aqua: v0.7.3 =&amp;gt; v0.7.10  aqua-registry: v0.</description>
    </item>
    
    <item>
      <title>2021-09 やったこと</title>
      <link>https://techblog.szksh.cloud/what-i-did-2021-09/</link>
      <pubDate>Sat, 02 Oct 2021 21:46:15 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/what-i-did-2021-09/</guid>
      <description>仕事 今月は有休消化やシルバーウィークもあり、稼働が少なく、あまり仕事が進まなかったです。
 AWS SSO や Organizations を導入するためのロードマップの策定 AWS SSO の検証  登壇  2021-09-30 HashiTalks Japan 2021 (youtube)  Terraform Platform in Quipper (youtube) Talk (30 min)    新たに作った OSS  aqua-renovate-config  Renovate Configuration to update packages and registries of aqua    Blog  English  Tips about Renovate 2021-09-08 aqua - Declarative CLI Version Manager   https://techblog.szksh.cloud/archives/2021/09/  2021-09-25 aqua で組織・チームのツール群を管理 2021-09-05 aqua の設定ファイルをインタラクティブに生成する generate コマンド 2021-09-04 aqua v0.</description>
    </item>
    
    <item>
      <title>aqua で組織・チームのツール群を管理</title>
      <link>https://techblog.szksh.cloud/aqua-global-configs/</link>
      <pubDate>Sat, 25 Sep 2021 12:01:56 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/aqua-global-configs/</guid>
      <description>aqua v0.7.3 をリリースし、 複数の global configuration をサポートしました。
個人で使う分にはあまり嬉しい機能でもないかもしれませんが、 会社・組織・チームといった集団(以下組織で統一)で設定を共有するには便利な機能だと思います。
これまで aqua では 2 つの設定ファイルをサポートしていました。
 -c で指定した場合はそのファイル、そうでなければカレントディレクトリから探索して最初に見つかったファイル  リポジトリ直下にそのリポジトリ用の aqua.yaml をおく   global configuration (デフォルトは ~/.aqua/global/[.]aqua.y[a]ml)  個人の dotfiles とかで aqua.yaml を管理しておく    こうすることで特定のリポジトリ用の設定と個人の設定を管理することができます。
しかし、第三の設定を参照することはできませんでした。 例えばある組織で使うツールセットを aqua で管理しようと思ってもこれまでは難しかったです。
そこで AQUA_GLOBAL_CONFIG という環境変数に : 区切りで設定ファイルへのパスを設定することで先頭から順に設定ファイルを参照するようにしました。
設定ファイルの優先順位は高い方から順に次のようになります。
 -c で指定した場合はそのファイル、そうでなければカレントディレクトリから探索して最初に見つかったファイル AQUA_GLOBAL_CONFIG global configuration (デフォルトは ~/.aqua/global/[.]aqua.y[a]ml)  イメージとしては
 プロジェクト(リポジトリ)の設定 組織の設定 個人の設定  という感じです。
例えば GitHub Organizations に aqua-config というリポジトリを作成し、以下のようなファイルを用意したとしましょう。
 all.</description>
    </item>
    
    <item>
      <title>aqua の設定ファイルをインタラクティブに生成する generate コマンド</title>
      <link>https://techblog.szksh.cloud/aqua-generate/</link>
      <pubDate>Sun, 05 Sep 2021 10:17:39 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/aqua-generate/</guid>
      <description>aqua - CLI ツールのバージョン管理 aqua v0.1.0 から v0.5.0 での変更点  aqua v0.5.1 で追加された generate というサブコマンドを紹介します。
aqua では Registry を活用することで設定を記述する手間を省くことができますが、 Registry を活用するには、インストールしたいツールが Registry で定義されているか、されているとしたら name はなにか調べる必要があります。 Registry で定義されているのに見逃してしまうこともあるでしょう。
また、 aqua でツールをインストールするには version を指定する必要がありますが、多くの場合はとりあえず最新バージョンはなにかを調べることになるでしょう。
これらの手間を減らすために generate というインタラクティブなコマンドを追加しました。 これは aqua.yaml で指定されている Registry で定義されている packages の一覧から package を fuzzy search によって選択し、 更に github_release package の場合は release version の一覧を fuzzy search によって選択することで package の YAML 定義を出力するコマンドです。
使ってみるのが早いでしょう。 aqua.yaml に Standard Registry を追加した上で aqua g を実行してみます。</description>
    </item>
    
    <item>
      <title>aqua v0.1.0 から v0.5.0 での変更点</title>
      <link>https://techblog.szksh.cloud/aqua-v0.5/</link>
      <pubDate>Sat, 04 Sep 2021 11:58:42 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/aqua-v0.5/</guid>
      <description>先日 aqua v0.1.0 をリリースした記事を書いたばかりですが、 そこから更に開発を続けて v0.5.0 をリリースしたので、変更点を紹介します。
基本的に Release Note に書いてあるとおりです。
 PATH を project (aqua.yaml) 毎に設定する必要がなくなりました  ~/.aqua/bin を PATH に追加すればよくなりました direnv などを使って環境変数を追加する必要がなくなりました   install コマンドに --test option を追加し、 file.src の設定が正しいかテストできるようになりました  CI で aqua の設定をテストするのに便利   GitHub Release だけでなく、任意の URL から tool のダウンロード・インストールができるようになりました  Go や helm, Hashicorp の product のような公式サイトからダウンロードするタイプのツールも install できるようになりました   Breaking Change: inline_registry の設定の形式を変更しました aqua の設定の再利用性を高める Registry という仕組みを導入しました  standard Registry を公開しました https://github.</description>
    </item>
    
    <item>
      <title>2021-08 やったこと</title>
      <link>https://techblog.szksh.cloud/what-i-did-2021-08/</link>
      <pubDate>Thu, 02 Sep 2021 14:33:16 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/what-i-did-2021-08/</guid>
      <description>仕事  AWS IAM User を削除する際に force_destroy が true になっているか Conftest でテスト Terraform の State 分割 Terraform Modules を別リポジトリで管理して versioning git-secrets を secretlint に移行  git-secrets がメンテされてなくて、既知バグが放置されているから   CI で terraform fmt によるフォーマットの自動化 WIP: AWS WAF の COUNT, BLOCK ログを Firehose で抽出 WIP: AWS CodeBuild で Provisioning Error が発生したら自動で Retry WIP: AWS CodeBuild のための GitHub App の開発 WIP: AWS SSO について調査  OSS Contribution Renovate の GitHub Actions のドキュメントの修正をしました。 ドキュメント中に書かれたバージョンを Renovate で自動 update するようにしました。</description>
    </item>
    
    <item>
      <title>aqua - CLI ツールのバージョン管理</title>
      <link>https://techblog.szksh.cloud/aqua/</link>
      <pubDate>Sat, 28 Aug 2021 09:07:38 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/aqua/</guid>
      <description>2021-09-04 追記: aqua v0.1.0 から v0.5.0 での変更点
aqua という OSS を開発しているので紹介します。
記事の内容は aqua v0.1.0 に基づきます。将来的に仕様が変わる可能性があります。
aqua とは aqua は CLI ツールのバージョン管理のための CLI です。 aqua で管理する主な対象は GitHub Release で公開されているツールです。 YAML の設定ファイルを書いてコマンドを実行すると指定したツールをインストールすることができます。
例えば以下のような設定ファイルを書き、 aqua install というコマンドを実行すると jq, conftest などが GitHub Release からダウンロードされ、インストールされます。
packages: - name: jq registry: inline version: jq-1.6 - name: conftest registry: inline version: v0.27.0 inline_registry: - name: jq type: github_release repo_owner: stedolan repo_name: jq asset: &amp;#39;jq-{{if eq .OS &amp;#34;darwin&amp;#34;}}osx-amd64{{else}}{{if eq .</description>
    </item>
    
    <item>
      <title>2021-07 やったこと</title>
      <link>https://techblog.szksh.cloud/what-i-did-2021-07/</link>
      <pubDate>Wed, 28 Jul 2021 06:58:45 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/what-i-did-2021-07/</guid>
      <description>今まで仕事に限定して書いてきましたが、 OSS 活動なんかにも触れてもいいんじゃないかと思ったので分かる範囲で書きます。
仕事  Docker Image を Docker Hub から ECR へ移行 Terraform  .terraform.lock.hcl を CI の中で自動で更新(commit, push)できるようにした  Terraform に詳しくない人も使うので、自動化したほうが良いと判断   tfmigrate を CI に導入 (in progress) Terraform Modules を Terraform の Monorepo とは別リポジトリで管理して versioning するようにした Route53 の管理を Roadworker から Terraform へ移行 tfmigrate を使ったリファクタリング    Event  Open Policy Agent Rego Knowledge Sharing Meetup で登壇  https://gist.github.com/suzuki-shunsuke/9372337aa62a6f8394bb136582ec068e    OSS Contribution AWS AppConfig を Terraform で管理できるようにする PR が無事マージされました。</description>
    </item>
    
    <item>
      <title>terraformer で雑に生成した tf ファイル と state を分割したくてツールを書いた</title>
      <link>https://techblog.szksh.cloud/tfmigrator/</link>
      <pubDate>Sun, 31 Jan 2021 14:53:23 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/tfmigrator/</guid>
      <description>terraformer で雑に生成した Terraform の設定ファイル (以下 tf ファイル) と state を分割したくてツールを書きました。
tfmigrator
経緯 miam から Terraform へ移行したい miam というツールで管理されている大量のリソースを Terraform で管理したくなりました。 多くの AWS Resource は Terraform で管理されていますが、 IAM に関しては miam で管理されています。 なぜ Terraform ではなく miam で管理されているかというと、当時のことは自分には分かりませんが、歴史的な経緯もあると思います。 昔は今よりも Terraform の表現力が豊かではなく、 Ruby で自由にかける miam のほうが扱いやすかったとか、 miam だと miam でリソースを管理することを強制できるため、権限管理を厳格にやるという観点では都合が良いという点もあるかと思います。
ではなぜ Terraform で管理したくなったかというと、 一番大きな理由は miam で頻繁に rate limit に引っかかるようになったからです。 Terraform にしろ miam にしろ CI/CD で test, apply が実行されるようになっています。 miam では毎回全部のリソースを対象に処理が実行されるため、リソースの数が増えるにつれて rate limit に引っかかりやすくなります。 CI を rerun すれば成功するのですが、悪いときは 3 回連続で rate limit に引っかかり、 4 回目でようやく成功するということもありました。</description>
    </item>
    
    <item>
      <title>tfnotify を fork した</title>
      <link>https://techblog.szksh.cloud/fork-tfnotify/</link>
      <pubDate>Sat, 02 Jan 2021 19:42:10 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/fork-tfnotify/</guid>
      <description>mercari/tfnotify を Fork して 2 つほど OSS を作りました。
 https://github.com/suzuki-shunsuke/tfnotify - tfnotify と互換性あり https://github.com/suzuki-shunsuke/tfcmt - tfnotify と互換性がない  開発の経緯 これまで tfnotify を便利に使わせてもらってたのですが、幾つか改善したいと思うところがあり、本家に PR を投げました。 しかし残念ながらこれまでのところ反応がなく、そこまで本家が活発ではないこと、また他にも色々改修したいところがあったことから、自分でフォークしてメンテすることにしました。 最初は互換性を維持しながら suzuki-shunsuke/tfnotify を開発していました(今もしています)。 しかし、開発を進めるに連れ、自分にとって必要のないプラットフォームなどに関するコードが邪魔であると感じ、それらを消したバージョンを別に開発することにしました。 互換性がなくなることから、名前も変えて tfcmt としました。
https://github.com/suzuki-shunsuke/tfcmt
こういった経緯から、 tfcmt のほうを優先的に開発していますが、 tfcmt で実装した機能を後から suzuki-shunsuke/tfnotify にも実装してたりもします。
Fork 元のバージョン suzuki-shunsuke/tfnotify は mercari/tfnotify v0.7.0 fb178d8 をフォークしました。 一方 tfcmt は suzuki-shunsuke/tfnotify v1.3.3 をフォークしました。
mercari/tfnotify との違い 本家との違いは Release Note とドキュメントを参照してください。
 suzuki-shunsuke/tfnotify  https://github.com/suzuki-shunsuke/tfnotify/releases https://github.com/suzuki-shunsuke/tfnotify/blob/master/COMPARED_WITH_TFNOTIFY.md   suzuki-shunsuke/tfcmt  https://github.com/suzuki-shunsuke/tfcmt/releases https://github.</description>
    </item>
    
    <item>
      <title>Terraform の Docker Provider の Collaborator になりました</title>
      <link>https://techblog.szksh.cloud/collaborator-of-terraform-docker-provider/</link>
      <pubDate>Thu, 03 Dec 2020 09:07:32 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/collaborator-of-terraform-docker-provider/</guid>
      <description>先日 kreuzwerker/terraform-provider-docker の Collaborator になりました。 kreuzwerker/terraform-provider-docker は Terraform の Docker Provider であり、 Docker コンテナや image, network などを管理できます。 元々は Hashicorp の Official Provider であった terraform-providers/terraform-provider-docker が kreuzwerker/terraform-provider-docker に移管され、 Community Provider になりました。 元のリポジトリは hashicorp org に移され archive されています。
Collaborator になった経緯 リポジトリが移管される際に、メンテナを募集していて過去に contribution していた自分にも声をかけていただきました。
https://github.com/hashicorp/terraform-provider-docker/issues/306
Contributor になった経緯 自分がこの provider に contribution した経緯は、 Terraform の Hands on を書くのに丁度よい provider を探していたことでした。
Hands on の題材として Docker コンテナを作ったりできたらいいんじゃないかなと思って Docker provider を試してみました。 しかし当時の docker_container リソースは read をちゃんとサポートしていませんでした。 なので import や update がまともに動きませんでした。 それを見かねて修正して PR を投げたのが最初です。</description>
    </item>
    
    <item>
      <title>Splitting .circleci/config.yml</title>
      <link>https://techblog.szksh.cloud/splitting-circleci-config/</link>
      <pubDate>Sat, 07 Nov 2020 14:43:10 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/splitting-circleci-config/</guid>
      <description>In this post I introduce how to split a huge .circleci/config.yml.
CircleCI doesn&amp;rsquo;t support to split .circleci/config.yml, so we manage all workflows and jobs configuration into one file .circleci/config.yml. If the repository is Monorepo, the more the number of services increases, the more the size of .circleci/config.yml becomes large and it&amp;rsquo;s hard to maintain .circleci/config.yml. By splitting .circleci/config.yml per service, it makes easy to maintain .circleci/config.yml and we can configure split file&amp;rsquo;s CODEOWNERS.</description>
    </item>
    
    <item>
      <title>github-ci-monitor: CI のステータスを DataDog で監視</title>
      <link>https://techblog.szksh.cloud/github-ci-monitor/</link>
      <pubDate>Sun, 01 Nov 2020 17:51:44 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/github-ci-monitor/</guid>
      <description>自作の OSS github-ci-monitor の紹介です。
GitHub リポジトリの CI のステータスを定期的に取得し、 DataDog に送ることで、 CI のステータスを監視するツールです。 現状は AWS Lambda で動かすことを想定していますが、他の方法でも動かせるようにするつもりです。
Motivation モチベーションは、 PR をマージしたあとに CI がこけた場合に通知が欲しいというものです。 マージしたあとに CI が一瞬で終わるなら無事終わるのを見届けてもいいんですが、 数分かかると待ってるのも時間がもったいないです。 しばらくしたあとに結果を確認すればいいんですが、それも面倒くさいですし、普通に忘れます。 そうするとデプロイしたつもりが実は CI がこけてたなんてことが普通にあります。
そういうことにすぐ気づけるよう、 Slack に通知がほしいと思っていました。
仕組み 仕組みは単純です。
GitHub API で各リポジトリのステータスを取得し、 DataDog API でステータスを送信しています。 DataDog API は Service Check API を使っています。 status は以下のようになります。
 0: 正常 1: 異常 3: ステータスの取得に失敗  また以下の tag が付きます。
 owner: リポジトリのオーナー repo: リポジトリ名 ref: ブランチ名  各リポジトリのステータスは現状 3 つをサポートしています。</description>
    </item>
    
    <item>
      <title>matchfile - 変更されたファイルの一覧から必要なタスクを導出するための CLI ツール</title>
      <link>https://techblog.szksh.cloud/matchfile/</link>
      <pubDate>Tue, 27 Oct 2020 19:39:44 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/matchfile/</guid>
      <description>自作の CLI ツール matchfile について紹介します。
https://github.com/suzuki-shunsuke/matchfile
この記事の執筆時点で最新バージョンは v0.1.1 です。
変更されたファイルの一覧から実行する必要のあるタスクを導出するための CLI ツールです。 Go で書かれていて、バイナリをダウンロードしてくれば使えます。
Pull Request (以下 PR) の CI では PR で変更されたファイルに応じて 必要なタスク(build, test, lint, etc) だけを実行したかったりします。
そこで、 PR で変更されたファイルパスのリスト と タスクが依存するファイルパスの条件 を元に、そのタスクを実行する必要があるか判定するためのコマンドとして matchfile を開発しました。
ただし、 matchfile の機能としては PR や CI とは独立しているので、もっと別の目的でも使えるとは思います。
matchfile は PR で変更されたファイルパスのリスト や タスクが依存するファイルパスの条件 を取得したりする機能はありません。
PR で変更されたファイルパスのリスト は ci-info という自分が作った別のツールを使うと取得できます。
タスクが依存するファイルパスの条件 はタスクに大きく依存するので matchfile はカバーしていません。
matchfile の使い方としては
$ matchfile run &amp;lt;PR で変更されたファイルパスのリストが書かれたファイルへのパス&amp;gt; &amp;lt;タスクが依存するファイルパスの条件が書かれたファイルへのパス&amp;gt; で、 PR で変更されたファイルパスのリスト のうち一つでも タスクが依存するファイルパスの条件 にマッチすれば true を、マッチしなければ false を標準出力します。 コマンドの exit code で結果を表現することも考えられましたが、そうすると set -e しているときに若干面倒くさいので、標準出力で表現しました。</description>
    </item>
    
    <item>
      <title>なぜ buildflow を作ったのか</title>
      <link>https://techblog.szksh.cloud/buildflow-goal/</link>
      <pubDate>Sun, 18 Oct 2020 09:53:08 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-goal/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書きます。
この記事では なぜ buildflow を作ったのかについて説明します。 開発者である自分の好みや置かれた環境などが所々に反映された内容になっています。
解決したい課題 自分は CI/CD の DX の改善に業務として取り組んでいます。 リポジトリはたくさんあり、横断的にメンテナンスしています。 幾つかのリポジトリはモノレポになっており、 CI の複雑さが増していたり、 CI の実行時間が長かったりします。
現在の CI/CD には以下のような問題があると感じています(他にもあるんですが、 buildflow と関係ないので割愛)。
 実行時間が長い  PR とは関係ない処理(test, build, etc) が実行されている   金銭的に高い  実行時間が長いので無駄にお金がかかっている CI サービスによっては並列度を上げることで実行時間が縮む場合があるが、それでもその分お金がかかる   PR とは直接関係ないところで失敗する  PR とは関係ない処理(test, build, etc) が実行されていて、それらが flaky で失敗する   メンテナンス性が悪い  属人化気味 何をやっているのか分かりにくい   同じような機能を複数のリポジトリで実装・メンテしたくない  これらの問題を解決するために buildflow を開発しました。
buildflow で必要な処理だけを実行する buildflow では PR の情報を自動で取得し、それらに応じて実行する処理を変更できます。 変更されたファイルに応じてだけでなく、 label や PR の author などでも変更できます。 Tengo script を用いて柔軟なロジックを実装できます。 JSON や YAML の読み込みもサポートしているので、依存関係などの設定を別ファイルで管理することも出来ます。</description>
    </item>
    
    <item>
      <title>buildflow の実行結果の出力形式</title>
      <link>https://techblog.szksh.cloud/buildflow-result-output/</link>
      <pubDate>Sun, 18 Oct 2020 08:36:09 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-result-output/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書きます。
この記事では buildflow の実行結果の出力フォーマットなどについて説明します。
ちょっと出力はわかりにくいかもしれません。 改善したいと思いつつ、どうあるべきなのかまだ見えてないのでこんな感じになっています。
task の標準出力、標準エラー出力はリアルタイムで出力されます。 また、複数のタスクを並列実行できます。 複数のタスクのログをリアルタイムで出力すると当然混じるので、区別がつくように各行の prefix に timestamp | task name |  をつけて出力します。 それでも混じるとわかりにくいので、 phase が完了後に、 phase の全 task のログを混ざらないようにそれぞれ標準エラー出力します。 つまり同じログが 2 回出力されますが 2 回実行されているわけではないです。
============== = Phase: phase 名 = ============== 10:47:54UTC | task A | + /bin/sh -c echo hello # 実行されるコマンド 10:47:54UTC | task B | + /bin/sh -c echo foo 10:47:54UTC | task A | hello # コマンドの標準(エラー)出力 10:47:54UTC | task A | .</description>
    </item>
    
    <item>
      <title>buildflow が自動で取得する Pull Request の情報</title>
      <link>https://techblog.szksh.cloud/buildflow-pr-info/</link>
      <pubDate>Sun, 18 Oct 2020 08:13:48 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-pr-info/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書きます。
この記事では buildflow が自動で Pull Request (以下 PR) の情報を取得してくる機能について説明します。
この機能は GitHub のみサポートしています。 GitLab や BitBucket はサポートしていません。 これは単純に自分が GitHub しか使わないからです。
PR の CI では
 変更されたものだけテストする 特定の PR ラベルがついていたら実行する 特定のユーザーの PR だけ処理を変える(bot とか)  のように PR の情報に基づいて挙動を変えたくなったりします。
シェルスクリプトで GitHub API 叩いて情報とってきて jq でパースしてとか、頑張れば別にできるんですが、 毎回そういうコードを書きたくないなと感じていました。
なお、 PR の情報をとってくる機能はデフォルトで無効化されています(GitHub Access Token 必要ですしね)。 設定で pr: true を指定してください。
PR の情報をとってくるには、以下の情報が必要です。
 repository owner: 設定ファイルで owner を設定するか、自動取得。 owner を設定してある場合はそちらが優先される repository name: 設定ファイルで repo を設定するか、自動取得。 repo を設定してある場合はそちらが優先される pull request number: 自動取得 GitHub Access Token: 環境変数 GITHUB_TOKEN または GITHUB_ACCESS_TOKEN を指定してください  取得される情報 以下のパラメータがテンプレートや Tengo script に渡されます。</description>
    </item>
    
    <item>
      <title>buildflow ではなぜ Tengo を採用しているのか</title>
      <link>https://techblog.szksh.cloud/buildflow-why-tengo/</link>
      <pubDate>Sat, 17 Oct 2020 22:35:56 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-why-tengo/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書きます。
この記事では buildflow でなぜ Tengo を採用しているのかについて説明します。
https://github.com/d5/tengo
Tengo に関しては https://techblog.szksh.cloud/buildflow-1/ でも多少触れています。
なぜ Tengo を採用しているのかに関しては
 なぜスクリプト言語を採用しているのか なぜ他の言語ではなく Tengo なのか  の 2 つの観点で話します。
なぜスクリプト言語を採用しているのか 逆にスクリプト言語を採用しない方法としては、 YAML などで独自 DSL のようなものを定義する方法があります。 DSL と言うと大げさかもしれませんが、 AND, OR, NOT といった論理を YAML のようなデータ記述言語で表現しようと思うとそんな感じになると思います。
この方法は扱いたいロジックが単純なものに限られるのであれば問題ないですが、 より柔軟なロジックを表現したいとなった場合に、無理があります。
 どうやって表現すればいいのか自分で考えないといけない  どう頑張っても独自ルールになるため、ユーザーにとって直感的とは言えない   正しく実装しないといけない 仕様をドキュメント化しないといけない  一方、 Go では幾つかのスクリプト言語がサードパーティのライブラリとして実装されており、 buildflow のようなツールに組み込むことが出来ます。
https://github.com/avelino/awesome-go#embeddable-scripting-languages
これらを活用すれば上記の問題は解決できるうえに、非常に柔軟にロジックを実装できます(勿論言語によりますが)。
なぜ他の言語ではなく Tengo なのか 単純に https://github.com/avelino/awesome-go#embeddable-scripting-languages で紹介されているライブラリの中で一番要件にマッチしてそうだったからです。 といっても全てをちゃんとチェックしたわけではありませんが。 Lua とかもあるのでそれでも良かったかもですが、自分は Lua を全然知りません。 あとちゃんとバージョンニングされていたのも理由の一つです。 Tengo より人気のある言語もありましたが、バージョニングされてないという理由で見送ったりしました。</description>
    </item>
    
    <item>
      <title>buildflow の dynamic task</title>
      <link>https://techblog.szksh.cloud/buildflow-dynamic-task/</link>
      <pubDate>Sat, 17 Oct 2020 21:29:51 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-dynamic-task/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書きます。
この記事では buildflow の dynamic task という機能について説明します。 dynamic task では task.items の値でループを回し、複数の task を動的に生成できます。 勿論 task.items はオプションなので、指定しなければ普通の task として扱われます。 task.items を指定する場合、 map か list か、それらを返す Tengo script でないといけません。
--- phases: - name: main tasks: - name: &amp;#34;list {{.Item.Key}} {{.Item.Value.name}}&amp;#34; command: command: &amp;#34;echo {{.Item.Key}} {{.Item.Value.name}} {{.Item.Value.age}}&amp;#34; items: - name: foo age: 10 - name: bar age: 20 上記の設定は dynamic task を使わないとこうなります。
--- phases: - name: main tasks: - name: &amp;#34;list 0 foo&amp;#34; command: command: &amp;#34;echo 0 foo 10&amp;#34; - name: &amp;#34;list 1 bar&amp;#34; command: command: &amp;#34;echo 1 bar 20&amp;#34; パラメータ Item は Key, Value を持ち、 Items が map の場合、それぞれ map の key, value が渡され、 list の場合、 index と value が渡されます。</description>
    </item>
    
    <item>
      <title>buildflow の task の input, output という機能</title>
      <link>https://techblog.szksh.cloud/buildflow-input-output/</link>
      <pubDate>Sat, 17 Oct 2020 21:05:41 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-input-output/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書きます。
この記事では buildflow の task の input, output という機能について説明します。 task の input, output は Tengo script で task のパラメータを整形する機能です。
task の command.command や write_file.template など、幾つかの設定では Go の text/template が使えますが、 text/template は複雑なロジックを記述したりするのには向いていません。 そこで task の input で Tengo script を使って必要なデータの整形を行うことで、 template は比較的きれいな状態に保つことが出来ます。
これは MVC モデルで View とロジックを分離するみたいな考え方と似ているかもしれません。
output ではコマンドの実行結果を整形することが出来ます。 例えばコマンドの標準出力をユニークな文字列のリストにしたり出来ます。
task.input は task.when が評価されたあと、 task の command などが実行される前に評価されます。 つまり、 task.when や task.dependency で同じ task の input の結果を参照は出来ません。</description>
    </item>
    
    <item>
      <title>buildflow で設定ファイルを分割する</title>
      <link>https://techblog.szksh.cloud/buildflow-split-files/</link>
      <pubDate>Sat, 17 Oct 2020 20:49:28 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-split-files/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書こうかなと思います。
この記事では buildflow の設定ファイルを分割する方法について説明します。
buildflow では一部の設定項目について他のファイルのパスを指定して読み込むということが出来ます。 1 つのファイルに全部の設定を書いていると、ファイルが大きくなってメンテナンス性が悪くなったり、 コードオーナーが曖昧になったりするので、そういう場合は分割すると良いでしょう。 コードオーナーが異なる複数のサービスで共通の設定ファイルを用いる場合、ファイルを分割して GitHub の CODEOWNERS を設定するのもよいでしょう。 あまりないかもしれませんが、ファイルを分割すると同じファイルを読み込んで再利用も出来ます。
また、 Tengo script を独立したファイルに分割すると、 test が可能になります。 Tengo script をテストするためのツールとして tengo-tester というツールも開発しているので、そちらをお使いください。
以下のようなファイル読み込みの設定があります。
 phase.import task.import: task.input_file task.output_file task.when_file command.command_file command.env[].value_file write_file.template_file  ファイルのパスは、絶対パスか、実行中の build の設定ファイルが存在するディレクトリからの相対パスになります。</description>
    </item>
    
    <item>
      <title>buildflow の script や template に渡される parameter</title>
      <link>https://techblog.szksh.cloud/buildflow-parameter/</link>
      <pubDate>Sat, 17 Oct 2020 19:44:39 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-parameter/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書こうと思います。
この記事では buildflow の Tengo script やテンプレートにパラメータとして渡される変数について紹介します。
buildflow では Tengo script はテンプレートが使える設定項目が多くあります。それらの設定には共通のフォーマットのパラメータが渡されます。
 PR: Pull Request の情報: GitHub API のレスポンス body Files: Pull Request で更新されたファイルの一覧: GitHub API のレスポンス body Phases: 対象の Phase よりも前の Phase の結果 Phase: 対象の Phase Tasks: 対象の Phase の Task の結果 Task: 対象の Task Item: dynamic task のパラメータとして渡される Meta: 設定 meta  Phase
 Status: Phase の実行結果  succeeded failed skipped   Tasks: Phase の task の実行結果 Meta: phase の 設定 meta  Task</description>
    </item>
    
    <item>
      <title>buildflow の task の設定項目</title>
      <link>https://techblog.szksh.cloud/buildflow-task/</link>
      <pubDate>Sat, 17 Oct 2020 18:26:57 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-task/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書こうと思います。
この記事では buildflow の task の基本的な設定項目などについて説明します。 数が多いので、個々の設定の詳細はまた別の記事に書きます。
task には幾つか type がありますが、全ての type に共通するパラメータが以下になります。
 name: task 名。 unique である必要はない。 Go の text/template が使える when: task を実行するか否か。 真偽値か Tengo script  when_file で外部ファイルを読み込める   dependency: task の依存関係の定義。 task 名のリストか、 Tengo script items: dynamic task の設定。 loop を使って複数の task を動的に生成できる  任意の list か map か、 Tengo script   input: Tengo script で task のコマンドのパラメータを生成できる  input_file で外部ファイルを読み込める   output: Tengo script で task の実行結果を整形できる。他の task が参照して挙動を変えたりできる  output_file で外部ファイルを読み込める   meta: ユーザーが自由にパラメータを定義できる map  上記の設定は name 以外はオプションです。</description>
    </item>
    
    <item>
      <title>buildflow の build, phase, task について</title>
      <link>https://techblog.szksh.cloud/buildflow-build-phase-task/</link>
      <pubDate>Sat, 17 Oct 2020 18:09:19 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-build-phase-task/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書こうと思います。
この記事では buildflow の概念である build, phase, task について書きたいと思います。
buildflow には Build, Phase, Task という概念があります。 CircleCI の Pipeline, Workflow, Job みたいなものと思ってもらえるとよいと思います。
$ buildflow run で 1 つの build が実行されます。 build は複数の phase からなり、 phase が 1 つずつ順に実行されます。 phase は複数の task からなり、 task が全て終了すると、その phase も終了となります。 task は並列に実行したり、依存関係を定義したりできます。 task では外部コマンドを実行したりできます。
設定ファイルでは phases, tasks をそれぞれ配列で指定します。
--- phases: - name: setup tasks: - name: hello command: command: echo hello - name: foo command: command: echo foo - name: build tasks: - name: hello command: command: echo hello - name: foo command: command: echo foo dependency: - hello - name: post build tasks: - name: hello command: command: echo hello 上の例では 3 つの phase setup, build, post build が順に実行されます。 デフォルトではどれかの phase が失敗するとそれ以降の phase は実行されません(この挙動は変えられます)。</description>
    </item>
    
    <item>
      <title>buildflow での Tengo の使い方</title>
      <link>https://techblog.szksh.cloud/buildflow-tengo/</link>
      <pubDate>Sat, 17 Oct 2020 17:18:34 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-tengo/</guid>
      <description>buildflow というツールを開発しているので buildflow というタグをつけて何回かに分けてブログを書こうかなと思います。
この記事では buildflow で Tengo というスクリプト言語をどのように使っているか書きたいと思います。
https://github.com/d5/tengo
buildflow の設定では task.when や task.dependency, task.input などで Tengo script が使えますが、 1 つの共通のルールがあります。 result という変数を宣言し、 script の実行結果をその変数に持たせるというルールです。 これは Tengo の仕様とかではなく、 buildflow 特有のルールです。 もっとも単純な例だと次のような感じです。
result := true task.input, output などだと result の値が Task.Input, Task.Output として参照できるようになります。
--- phases: - name: main tasks: - name: hello input: |result := { foo: &amp;#34;bar&amp;#34; } command: command: &amp;#39;echo &amp;#34;{{.Task.Input.foo}}&amp;#34;&amp;#39; when: &amp;#34;result := true&amp;#34; Tengo の標準ライブラリ Tengo には標準ライブラリがあります。 buildflow では全ての標準ライブラリが使えます。</description>
    </item>
    
    <item>
      <title>buildflow というワークフローエンジンのようなタスクランナーのようなツールを作っている</title>
      <link>https://techblog.szksh.cloud/buildflow-1/</link>
      <pubDate>Sat, 17 Oct 2020 16:06:31 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/buildflow-1/</guid>
      <description>buildflow というツールを開発しているので紹介します。 buildflow というタグをつけて何回かに分けてブログを書こうかなと思います。 1本目のこの記事では
 どんなツールか Hello World 特徴  について簡単に説明します。
どんなツールか https://github.com/suzuki-shunsuke/buildflow
ワークフローを実行するための CLI ツールです。 ワークフローエンジンと言うと Airflow とか Azkaban, Argo Workflows のようなツールをイメージするかと思いますが、 それらとは目的も機能も違います。 一部の CI サービスではワークフローのローカル実行をサポートしてたりしますが、そんなイメージで良いかもしれません。 buildflow では task と task の依存関係を設定ファイルに定義し、コマンドを実行するとローカルでタスクが実行されます。 そういうとタスクランナーといったほうがいいのかもしれませんが、個別のタスクを指定して実行するような機能はないので、タスクランナーとも違う気がします。
CI サービス上で実行することを目的として開発しています(汎用的なツールなので他の目的でも使えるとは思います)。
Hello World まだどんなツールかピンと来てない人もいるかもしれないので、簡単な Hello World をやってみましょう。
GitHub Releases からバイナリをダウンロードしてください。
次のような設定ファイル .buildflow.yaml を用意します。
--- phases: - name: main tasks: - name: hello command: command: echo hello 次のコマンドを実行すると task が実行されます。
$ buildflow run ============== = Phase: main = ============== 07:50:46UTC | hello | + /bin/sh -c echo hello 07:50:46UTC | hello | 07:50:46UTC | hello | hello 07:50:46UTC | hello | ================ = Phase Result: main = ================ status: succeeded task: hello status: succeeded exit code: 0 start time: 2020-10-17T07:50:46Z end time: 2020-10-17T07:50:46Z duration: 4.</description>
    </item>
    
    <item>
      <title>github-comment - GitHub にコメントを投稿する CLI</title>
      <link>https://techblog.szksh.cloud/github-comment/</link>
      <pubDate>Fri, 31 Jul 2020 20:42:54 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/github-comment/</guid>
      <description>GitHub の issue や pull request, commit にコメントを投稿する CLI ツールを作りました(結構前の話ですが)。
https://github.com/suzuki-shunsuke/github-comment
このブログの執筆時点で最新は v1.5.0 です。
Go 製なので、 GitHub Releases からダウンロードしてくれば簡単にインストールできます。
想定している主な用途は、 CI/CD の 結果をコメントで通知することで DX を向上することです。 例えば CI がこけたらこけたコマンドとエラーメッセージを通知するなどです。
github-comment には
 init: 設定ファイルの雛形を生成する post: コメントを投稿する exec: 外部コマンドを実行し、その結果を元にコメントを投稿する  という 3 つのサブコマンドがあります。
コメントの投稿には GitHub の Access Token が必要です。 コマンドライン引数 -token でも渡せますが、環境変数として設定しましょう。
$ export GITHUB_TOKEN=xxx # GITHUB_ACCESS_TOKEN も可 post コマンド こんな感じでコメントを投稿できます。
$ github-comment post -org suzuki-shunsuke -repo github-comment -pr 1 -template test パラメータの数が多いですが、いくつかの Platform では環境変数から自動でパラメータを補完してくれます。</description>
    </item>
    
    <item>
      <title>clap - 簡単にツールをインストールするためのツールを作った</title>
      <link>https://techblog.szksh.cloud/clap/</link>
      <pubDate>Mon, 06 Jul 2020 16:52:58 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/clap/</guid>
      <description>多分車輪の再生産だとは思いますが、簡単にツールをインストールするための CLI ツールを作りました。 tarball や zip をダウンロードして展開して指定したパスにインストールするツールです。
https://github.com/suzuki-shunsuke/clap
Go で書かれています。 ツールの名前(clap)には特別な意味や理由はなく、なんとなくです。
CI で何かしらのツールをインストールすることがままあって、そのためのシェルスクリプトを都度書くのが割と面倒なのでツール化しました。
このブログを書いている時点でバージョンは v0.1.0-1 で、最低限の機能しかありませんが、9割型ニーズを満たせるかなと思います。
使い方は以下のようになっています。
$ clap &amp;lt;URL&amp;gt; &amp;lt;インストールするファイルのアーカイブ内での相対パス&amp;gt;:&amp;lt;インストール先&amp;gt; [&amp;lt;インストールするファイルのアーカイブ内での相対パス&amp;gt;:&amp;lt;インストール先&amp;gt;...] 例えば conftest を /usr/local/bin にインストールする場合次のようになります。
CONFTEST_VERSION=0.18.2 clap install https://github.com/instrumenta/conftest/releases/download/v${CONFTEST_VERSION}/conftest_${CONFTEST_VERSION}_Linux_x86_64.tar.gz conftest:/usr/local/bin/conftest chmod a+x /usr/local/bin/conftest パーミッションの付与はやってくれないので必要に応じてやってください。 ファイルの圧縮形式は URL から自動で判別してくれます。
上記の conftest のインストールを今までは次のようなシェルスクリプトを書いていました。
#!/usr/bin/env bash  set -eu CONFTEST_VERSION=0.18.2 dirpath=$(mktemp -d) pushd &amp;#34;$dirpath&amp;#34; TARFILE=conftest_${CONFTEST_VERSION}_Linux_x86_64.tar.gz curl -OL https://github.com/instrumenta/conftest/releases/download/v${CONFTEST_VERSION}/${TARFILE} tar xvzf $TARFILE mv conftest /usr/local/bin/conftest chmod a+x /usr/local/bin/conftest popd rm -R &amp;#34;$dirpath&amp;#34; 地味に面倒ですね。これをツール毎に書いて、しかも圧縮形式によって微妙に変えないといけません。</description>
    </item>
    
    <item>
      <title>Skaffold で特定のサービスだけ動かすためのツールを作った</title>
      <link>https://techblog.szksh.cloud/skaffold-generator/</link>
      <pubDate>Sun, 05 Apr 2020 18:53:25 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/skaffold-generator/</guid>
      <description>自作の CLI ツール skaffold-generator の紹介です。 プロトタイピングみたいなノリで半日くらいで割と手早く作れました。 名前が長くて適当なのでもっと良い名前ないかなと思ってます。
Skaffold に欲しい機能がないので補完する感じで作ったのですが、「それ〇〇で出来るよ」とかあったら(GitHub issue とか Twitter で)教えていただけると幸いです。
どんなツールか 設定ファイル skaffold-generator.yaml を監視して変更があったら skaffold.yaml を生成するツールです。設定ファイルでサービスの依存関係を定義できたり、コマンドライン引数で指定したサービス及びそれが依存するサービスに関連した設定だけを使って skaffold.yaml を更新します。 このツールは skaffold.yaml を生成するだけなので実際にアプリケーションをビルド・デプロイするには skaffold と組み合わせて使います。
なぜ作ったか 元々ローカルでアプリケーションを動かしながら開発するために Docker Compose を使ってるリポジトリがあるのですが、それを skaffold に移行出来ないか検証しています。 まだ skaffold を触り始めたばかりで理解が浅いのですが、 本番環境は k8s で動いてるからローカルも k8s で動かせるといいかなと思ったり、あとは変更を検知して自動でビルド・デプロイしてくれたりして便利そうかなと思いました。 まぁ結果的に移行しないことになったとしても、 Skaffold と現状の仕組みについて理解が深まればいいかなくらいのつもりです。
検証の過程で、 以下のようなことが Docker Compose だと出来るけど Skaffold だと難しそうだと思いました。
 サービスの依存関係を定義すること  Skaffold というより k8s の問題かとは思いますが Docker Compose だと依存するものを自動で起動してくれて便利   コマンドライン引数で指定したサービスだけ起動すること  Skaffold だと skafffold.yaml で定義したものすべてがビルド・デプロイされるという認識    サービスの数が少なければ全部ビルド・デプロイでもいいですが、 マイクロサービスをモノレポで管理しているような場合、 すべてのマイクロサービスをビルド・デプロイするのは無駄が大きかったりします。</description>
    </item>
    
    <item>
      <title>dd-time - コマンドの実行時間を Datadog に送るツール</title>
      <link>https://techblog.szksh.cloud/dd-time/</link>
      <pubDate>Sat, 30 Nov 2019 13:54:47 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/dd-time/</guid>
      <description>コマンドの実行時間を Datadog に送る dd-time というツールを作りました。
このツールは circle-dd-bench にインスパイアされていますが、 CircleCI 以外でも需要あると思ったり、他にも幾つか改善したい部分があったので自作することにしました。
circle-dd-bench については circle-dd-bench の作者が書いたブログ https://blog.yuyat.jp/post/circle-dd-bench/ も参考にしてください。
dd-time は Go 製なので GitHub Releases からバイナリをダウンロードしてインストールすれば使えます。
使い方はシンプルで実行時間を計測したいコマンドの前に dd-time -- をつけるだけです。 例えば Docker image のビルドの時間を計測したい場合次のような感じになります。
$ dd-time -t command:docker-build -- docker build . Datadog の API key を環境変数 DATADOG_API_KEY として設定する必要があります。 こうすると Datadog の Post timeseries points API を使い、command_execution_time というメトリックス名(変更可能)でコマンドの実行時間が送られます。
メトリックスの名前や host, tags はそれぞれ --metric-name (-m), --host, --tag (-t) で指定できます。 --tag は複数回指定可能で、 key:value というフォーマットで指定します。
CircleCI で実行した場合、 CircleCI のビルドイン環境変数が tag として勝手に設定されますが、 CircleCI 以外でも使えます。</description>
    </item>
    
    <item>
      <title>go-timeout - command の timeout</title>
      <link>https://techblog.szksh.cloud/go-timeout/</link>
      <pubDate>Mon, 04 Nov 2019 10:00:21 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/go-timeout/</guid>
      <description>作ったのは 2ヶ月くらい前の話ですが、 Go の command の timeout を実装するためのライブラリを作ったので紹介します。
https://github.com/suzuki-shunsuke/go-timeout
基本的には https://github.com/Songmu/timeout をオススメしますが、これだと上手くいかないパターンがあったので自作しました。
Go の command の timeout に関しては https://junkyard.song.mu/slides/gocon2019-spring/#24 がとても参考になります。
上記のスライドでは
 標準ライブラリの exec.CommandContext でも停止できるが、 SIGKILL で強制的に停止することになる  子プロセスが停止しない   公式見解 では、SIGKILL 以外は標準ライブラリではサポートしない。サードパーティでやればよい Songmu/timeout 使えば SIGKILL 以外でより安全に停止できる  ということが丁寧に説明されています。
自分は cmdx という task runner を開発していてその中で task の実行時に timeout を設定出来るようにしました。 当初 Songmu/timeout を使って実装したのですが、問題があることに気づきました。 それは、 command の中で fzf を使うと、上手く動かないというものでした。
 https://github.com/suzuki-shunsuke/cmdx/issues/52 https://twitter.com/szkdash/status/1165529415238815745  正直この辺の挙動はちゃんと理解できていないのですが、 調べてみると Songmu/timeout だと syscall.SysProcAttr の Setpgid を true に設定していて、そうすると fzf が上手く動かないようでした。</description>
    </item>
    
    <item>
      <title>cmdx - task runner</title>
      <link>https://techblog.szksh.cloud/cmdx/</link>
      <pubDate>Fri, 23 Aug 2019 11:35:13 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/cmdx/</guid>
      <description>最近自作した OSS, cmdx の紹介です。
https://github.com/suzuki-shunsuke/cmdx
cmdx は task runner です。
task runner の定義はググってもわからなかったので、 cmdx を task runner と呼ぶのが適切かわかりませんが、 ここではプロジェクト固有のタスク
 依存するライブラリのインストール ビルド テスト コード整形 lint etc  などを管理するものとします。
類似するものとしては以下のようなものがあります。
 Make npm scripts Task tj/robo mumoshu/variant  使い方 詳細は README を読んでください。
$ cmdx -i で設定ファイルの雛形を生成します。
そして設定ファイルに task を定義していきます。 設定に関しては README を参照してください。
そうすると cmdx -l でタスクの一覧とその説明が見れます。
例えば次は cmdx のリポジトリでの実行結果です。
$ cmdx -l init, i - setup git hooks coverage, c - test a package (fzf is required) test, t - test fmt - format the go code vet, v - go vet lint, l - lint the go code release, r - release the new version durl - check dead links (durl is required) ci-local - run the Drone pipeline at localhost (drone-cli is required) これにより新しくプロジェクトに参画した人もどのような task があるのか直ぐわかります。 例えば test を実行したければ cmdx t を実行すればいいことがわかります。 cmdx help test とすればここのタスクのより詳細なヘルプが見れます。</description>
    </item>
    
    <item>
      <title>Flute - Golang HTTP client testing framework</title>
      <link>https://techblog.szksh.cloud/fagott/</link>
      <pubDate>Sun, 07 Jul 2019 08:20:00 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/fagott/</guid>
      <description>2019-07-17 追記 プロジェクト名が変わりました
https://github.com/suzuki-shunsuke/flute/issues/20
 Go の HTTP client のテストフレームワークを作ったので紹介します。
https://github.com/suzuki-shunsuke/flute
執筆時点のバージョンは v0.6.0 です。
 リクエストパラメータのテスト HTTP サーバのモッキング  を目的としています。
比較的実践的なサンプルとして、ユーザーを作成する簡単な API client とそのテストを書いたので参考にしてください。
 https://github.com/suzuki-shunsuke/flute/blob/master/examples/create_user.go https://github.com/suzuki-shunsuke/flute/blob/master/examples/create_user_test.go#L17-L53  元々自分はこの目的のために h2non/gock を使っていました。 ただ、 gock だとリクエストがマッチしなかったときに、なぜマッチしないのかがわからず、調査に困るという問題がありました。
そこで flute では request に対し、matcher と tester という概念を導入し、 matcher でマッチしたリクエストを tester でテストするというふうにしました。 テストでは内部で stretchr/testify の assert を使っており、テストに失敗したときになぜ失敗したのかが分かりやすく出力されるようになっています。
例えば以下の例は、リクエストの Authorization header にトークンがセットされていなかった場合のエラーメッセージです。
=== RUN TestClient_CreateUser --- FAIL: TestClient_CreateUser (0.00s) tester.go:168: Error Trace: tester.go:168 tester.go:32 transport.go:25 client.go:250 client.go:174 client.</description>
    </item>
    
    <item>
      <title>Drone v0.8 の .drone.yml を v1 の .drone.jsonnet に変換するツールを作った</title>
      <link>https://techblog.szksh.cloud/drone-jsonnet-generator/</link>
      <pubDate>Wed, 12 Jun 2019 07:40:45 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/drone-jsonnet-generator/</guid>
      <description>Drone v0.8 の .drone.yml を v1 の .drone.jsonnet に変換するツールを作ったので紹介します。
https://github.com/suzuki-shunsuke/drone-jsonnet-generator
背景 https://docs.drone.io/user-guide/pipeline/migrating/
Drone は v0.8 から v1 で .drone.yml のフォーマットが大きく変わっています。 Drone v1 ではビルド実行時に自動で変換しているため、v0.8 の .drone.yml でもそのまま動きます(matrix builds も動きます)。
そのため、Drone v0.8 から v1 に移行する際、すぐに .drone.yml を修正しなくても問題ないのですが、 v1 独自の機能が出てきた場合 v0.8 のフォーマットの場合利用できないかもしれませんし、 いつまでも古いままだと気持ち悪いので出来るならフォーマットを変換したいです。
drone-cli ではフォーマットを変換する drone convert というコマンドが提供されています。
ただし、 drone convert は matrix build を multiple pipeline に変換するのですが、 非常に冗長になります。 そのため、jsonnet を利用することが推奨されています。
https://docs.drone.io/user-guide/pipeline/migrating/
 The above syntax can be quite verbose if you are testing a large number of variations.</description>
    </item>
    
    <item>
      <title>go-jsoneq - 2つの値がJSONとして等しいか比較するGoライブラリ</title>
      <link>https://techblog.szksh.cloud/go-jsoneq/</link>
      <pubDate>Thu, 23 May 2019 11:43:18 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/go-jsoneq/</guid>
      <description>https://github.com/suzuki-shunsuke/go-jsoneq
2つの値がJSONとして等しいか比較するGoライブラリを開発したので紹介します。
「2つの値がJSONとして等しい」とは、2つの値をそれぞれJSON文字列に変換したら、2つが表現するデータがおなじになるという意味です。
struct { Foo string `json:&amp;#34;foo&amp;#34;` }{ Foo: &amp;#34;bar&amp;#34;, } と
map[string]interface{}{&amp;#34;foo&amp;#34;: &amp;#34;bar&amp;#34;} を JSON に変換したらともに
{&amp;#34;foo&amp;#34;: &amp;#34;bar&amp;#34;} になりますね。
json.Marshaler のテストや、 実際の JSON 文字列から構造体を定義したときにちゃんと定義できているかチェックするのに使えると思います。
jsoneq.Equal でやっていることは単純です。
 json.Marshal で []byte に変換 json.Unmarshal で []byte を map, array と primitive な型からなるオブジェクト(?)に変換 reflect.DeepEqual で比較  引数が []byte の場合は 1 は飛ばします。
GoDoc やサンプルを見れば使い方は簡単にわかると思います。
以上、簡単ですが、自作ライブラリの紹介でした。</description>
    </item>
    
    <item>
      <title>durl - 壊れたURLを検知するCLIツール</title>
      <link>https://techblog.szksh.cloud/durl/</link>
      <pubDate>Sun, 28 Apr 2019 21:25:00 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/durl/</guid>
      <description>結構前に開発したツールですが、まだ記事にしてなかったので紹介します。
https://github.com/suzuki-shunsuke/durl
ファイル中の URL が壊れていないかチェックするツールです。 ファイル中の URL を抽出し、HTTPリクエストを投げてステータスコードが 2xx でないものがあった場合、異常終了します。
なお、ページ内リンク(アンカー)が壊れているものについては検知できません。
インストール Go製で、バイナリを GitHub Releases で公開しています。
https://github.com/suzuki-shunsuke/durl/releases
Docker イメージ https://quay.io/repository/suzuki_shunsuke/durl
busybox ベースの Docker イメージも提供しています。 CI で使うのに便利です。
使い方 durl init で設定ファイル .durl.yml を生成します。
$ durl init durl check に対象ファイルパスのリストを標準入力として渡してください。 find コマンドなどと組み合わせると良いです。
https://github.com/suzuki-shunsuke/go-errlog/blob/v0.9.0/scripts/durl.sh#L9
find . \ -type d -name node_modules -prune -o \ -type d -name .git -prune -o \ -type d -name vendor -prune -o \ -type f -print | \ grep -v package-lock.</description>
    </item>
    
    <item>
      <title>GraylogをTerraformで管理する</title>
      <link>https://techblog.szksh.cloud/graylog-terraform/</link>
      <pubDate>Sat, 01 Dec 2018 14:56:00 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/graylog-terraform/</guid>
      <description>Graylogのリソースを terraform で管理するために作った terraform provider を紹介します。 Graylogとは何かはこちらを読んでください。
Graylogには様々なリソースがあります。
 User Role Input Index Set Stream Stream Rule Dashboard Alert etc  これらのリソースはWeb UIから作成したり出来るわけですが、 Web UIでポチポチするのは疲れますし、ソースコードで管理したいものです(Infrastructure as Code)。 また、Web UIからでは細かな権限管理は出来ず(限られた権限管理しか出来ない)、APIを使ってする必要があります。
APIを使って管理できるツールを探したものの見つからなかったので、 APIを使ってGraylog用のterraform providerを自作しています。
https://github.com/suzuki-shunsuke/go-graylog
GraylogのAPIの種類は非常に多く、残念ながらカバーできているのは一部だけですが、以下のようなものをサポートしています。
 Alert Condition Alert Notification (Alarm Callback) Input User Role Index Set Stream Stream Rule Dashboard Ldap Setting  Role はサポートしているので権限管理は問題なく出来ます。 Dashboard Widget もサポートしたいです。
出来れば Alert の設定も出来ると良いのですが、Alertに関するCRUD APIが提供されていない(GETのみ)ので、サポートできません。
terraform を使った管理方法 以下では自分の管理方法を紹介します。
https://github.com/suzuki-shunsuke/example/tree/master/graylog-terraform
にサンプルが置いてあります。
基本はプロジェクトごとに
 Index Set, Stream, Role といったリソースを作成 User に Role を付与  という流れになります。</description>
    </item>
    
    <item>
      <title>Graylog で log を管理する</title>
      <link>https://techblog.szksh.cloud/graylog/</link>
      <pubDate>Tue, 27 Nov 2018 16:40:33 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/graylog/</guid>
      <description>Java 製の OSS ログ管理システム Graylog の紹介です。 Graylog については幾つかに分けて記事を書きたいと思います。 今回はGraylogの入門的な内容になります。
なお、本記事中で「現在」「現時点」といった場合、特に断りがなければ記事執筆時点 2018-11-27 を指します。
Graylog のバージョン 検証に用いるGraylogのバージョンは 2.4.6 になります。
OSSバージョンとEnterpriseバージョンがありますが、本記事ではOSSバージョンを使用します。
Graylog とは  https://www.graylog.org/ https://github.com/Graylog2/graylog2-server  Kibana と Elasticsearch(以下ES) を使ったことがある人は、Kibanaに代わるものだと思っていただくとイメージしやすいかと思います。 ログはGraylogそのものが保持するのではなく、ESにインデキシングされます。 Kibana同様、ESに収集されたログを検索したり、ダッシュボードを作ったり出来ます。 ダッシュボードに関してはKibanaのほうが優れているようにも思えますが、 Graylogは認証・認可によりダッシュボードやログを操作できる人を制限・管理することが出来ます。
Graylogでログを管理する場合、ユーザーは直接ESにはログを送らず、Graylogを経由して送ります。 ESに対するGraylog以外のアクセスを制限し直接ESにアクセスされるのを防ぐことが出来ます。
Graylog は多機能なシステムであり、ログを整形したり、アラートを飛ばしたり、他のシステムにログをフォワードしたりすることも出来ます。 marketplace でサードパーティの plugin が公開されており、機能を拡張することが出来ます。 APIも提供されており、ある程度自動化が可能です。
認証・認可 オンプレミスでログを管理する場合、社外からは勿論社内からのアクセスも制限したいです。 Graylog では LDAP や Active Directory によってアクセスを制限できます。 リソース毎に誰が何を出来るか設定できます。
http://docs.graylog.org/en/2.5/pages/users_and_roles/external_auth.html
ログの収集 ログの収集をするには Graylog で幾つかのリソースを作成する必要があります。
 Input Index Set Stream Stream Rule  Input はログの入力のフォーマットの設定であり、 どのポートでどういったフォーマットのログを受け付けるかという設定になります。 フォーマットは様々なものがサポートされています。
 AWS Flow Logs AWS Cloud Watch Logs AWS Cloud Trail Beats CEF AMQP CEF Kafka CEF TCP CEF UDP Fake HTTP Message GELF AMQP GELF HTTP GELF Kafka GELF TCP GELF UDP JSON Path NetFlow UDP Raw AMQP Syslog AMQP Syslog Kafka Syslog TCP Syslog UDP  この設定はログを収集するアプリケーションごとに設定するというより、グローバルな設定なので、他のアプリケーションで既に同じ形式でログを収集していたら新たに設定する必要はありません。</description>
    </item>
    
    <item>
      <title>akoi - binary installer</title>
      <link>https://techblog.szksh.cloud/akoi/</link>
      <pubDate>Wed, 31 Oct 2018 08:56:04 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/akoi/</guid>
      <description>自作のOSS akoi の紹介をします。
 なぜこんなものを作ったのか akoi と ansible を使ってサーバにバイナリをインストールする方法  について主に説明します。
まとめ  akoi はバイナリファイルのインストーラ 設定ファイルで管理できる 冪等であり、効率よくインストールできる  並列インストール Accept-Ranges による分散ダウンロード   ansibleでサーバにバイナリをインストールするのを補助してくれる  ansible で真面目にバージョンコントロールして効率よくインストールするのは難しい(ほとんどの ansible role は出来ていない)    akoi とは akoi はバイナリファイルのインストーラです。 設定ファイルにインストールするファイルのダウンロードURLとインストール先を記述して管理します。 インストールするバイナリのバージョン管理が可能であり、既にインストールしてあるバージョンへの切り替えはシンボリックを作り直すだけなので一瞬で終わります。無駄にダウンロードをしたりはしません。 複数のバイナリを並列でインストールしたり、Accept-Ranges ヘッダによる分散ダウンロードをサポートしています。
分散ダウンロードについては
https://qiita.com/codehex/items/d0a500ac387d39a34401
が参考になります。
Goで書かれています。
https://github.com/suzuki-shunsuke/akoi/releases からバイナリをダウンロードしてインストールできます。
詳細はREADMEを読んでください。
なぜ作ったのか サーバにバイナリをインストールする ansible role を書くのが辛かったからです。 最近は色々なソフトウェアがGoで書かれ、バイナリで配布されています。 そういったバイナリをサーバへインストールするのは ansible で行っているという方も少なくないのではないでしょうか？ 有名なソフトウェアをインストールする ansible role は大抵Ansible Galaxy で公開されています。
しかし、ほとんどの role は「真面目に」バージョン管理していません。 ここでいう「真面目に」とは
 バージョンを指定できる バージョンを変更できる 指定したバージョンが既にインストールされている場合は無駄にダウンロードしたりしない  といったことです。</description>
    </item>
    
    <item>
      <title>gomic - Goのモックジェネレータ</title>
      <link>https://techblog.szksh.cloud/gomic/</link>
      <pubDate>Tue, 30 Oct 2018 08:35:16 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/gomic/</guid>
      <description>自作のOSS gomic の紹介をします。
 なぜわざわざこんなものを作ったのか 生成されたモックの簡単な使い方  を主に説明したいと思います。
まとめ  gomic は Goのinterfaceを実装したモックを生成するCLIツール モックを手で書くのが辛すぎた &amp;amp; 既存ツールで満足できなかったため作った  自動生成できるコードは自動生成すべき   設定ファイルで管理するため、interfaceの更新に合わせてmockの更新が容易 生成されるモックはシンプルなAPIのみ提供するので学習コストが低い  gomic とは gomic は Goのinterfaceを実装したモックを生成するCLIツールです。 これによってモックを使ったテストの作成を効率化します。 単調な作業を自動化し、本来注力すべきことに注力できるようにするためのツールです。
Goで書かれています。
https://github.com/suzuki-shunsuke/gomic/releases からバイナリをダウンロードしてインストールできます。
同様のツールは幾つかあります。
 https://github.com/avelino/awesome-go#testing https://github.com/golang/mock (以下 gomock) https://github.com/gojuno/minimock (以下 minimock)  特に gomock は有名ですね。
なぜ作ったのか 上述のように既に同様のツールはありますし、 gomock と minimock は試しました。 しかしあまり満足のいくものではなかったため、自分で作ることにしました。
自分が欲しかったのは学習コストの低いシンプルなAPIです。 interfaceのメソッドを実装した関数をモックに渡すことで 簡単にメソッドの実装を切り替えたいのです。
// Getwd メソッドのモック mock.SetFuncGetwd(func() (string, error) { return &amp;#34;/tmp&amp;#34;, nil }) mock.Getwd() // &amp;#34;/tmp&amp;#34;, nil これは非常にシンプルで分かりやすく、柔軟性のあるパターンです(minimockはこのパターンもサポートしています)。</description>
    </item>
    
    <item>
      <title>go-gencfg - viperの個々のアプリケーション用のラッパーのコードジェネレータ</title>
      <link>https://techblog.szksh.cloud/go-gencfg/</link>
      <pubDate>Thu, 06 Sep 2018 23:59:35 +0900</pubDate>
      
      <guid>https://techblog.szksh.cloud/go-gencfg/</guid>
      <description>自作のOSS go-gencfg を紹介します。 Golang で viper という汎用的な設定管理ライブラリがありますが、 特定のアプリケーション用に viper のラッパーを生成するCLIツールです。
使い方や開発の背景を書こうかと思いましたが、だいたい README に書いてあるので そちらを御覧ください。
https://github.com/suzuki-shunsuke/go-gencfg/blob/master/README.md</description>
    </item>
    
  </channel>
</rss>
